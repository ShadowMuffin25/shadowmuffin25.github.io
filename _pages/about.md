---
permalink: /
title: "Anh Pham"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am a Master’s student in Computer Science at the University of Massachusetts Amherst, where I work with [Prof. Hong Yu](https://www.cics.umass.edu/about/directory/hong-yu) in the [BioNLP Lab](https://bio-nlp.github.io/index.html). My current research focuses on reinforcement learning with verifiable rewards for medical reasoning, exploring how factual, interpretable reward signals can guide models toward safer and more reliable clinical decision-making. Before joining the BioNLP Lab, I collaborated with mentors from Microsoft MAIDAP to improve the safety and efficiency of large language model fine-tuning. I also spent a summer as a Software Development Engineer Intern at Amazon, where I helped enhance identity management workflows for Amazon Connect. Earlier in my research journey, I worked with [Prof. Mai Elsherief](https://www.maielsherief.com/) at Northeastern University, where I explored applications of AI for social good, including projects on mental health discourse and emotional bias in language models.

At UMass, I also served as a core member of the [Public Interest Technology (PIT) Club](https://sites.google.com/umass.edu/pitumass?usp=share_link), organizing events and guest speaker sessions to promote the ethical and responsible use of technology across disciplines. Additionally, I have contributed as an Undergraduate Research Volunteer, working with PhD student [Kunjal Panchal](https://astuary.github.io/Kunjal/) on a survey of memory-efficient training methods for large language models.

I am broadly motivated by the question of **how to build AI systems that are not only capable, but also reliable, interpretable, and aligned with human values**. My long-term goal is to advance **AI for social good and safety**, bridging the gap between technical rigor and real-world responsibility. I am especially interested in combining interpretability, safety alignment, and human-centric evaluation to develop models whose reasoning can be understood, verified, and trusted.

---

## News
- **Nov 2025:** Presented a poster at **EMNLP 2025 (Industry Track)** on safe fine-tuning on a budget, in collaboration with Microsoft MAIDAP.
- **(In press)** *Fluent but Unfeeling: The Emotional Blind Spots of Language Models* — accepted to **ICWSM 2026**.  
- **Oct 2025:** Began project on reinforcement learning with verifiable rewards for medical reasoning in the UMass BioNLP Lab.  
- **Jan 2025:** Awarded the [Bay State Fellowship](https://www.cics.umass.edu/academics/scholarships-and-fellowships/bay-state-scholarship-program) in Computer Science at UMass Amherst.  
- **Sept 2024:** Presented at the [UMass JEDI Conference](https://www.umass.edu/dialogue/events/justice-equity-diversity-and-inclusion-jedi-conference-2024) on bias in machine learning.
- **Sept 2024:** Joined **BUILD UMass** to contribute to the development of a menstrual cycle tracker for low-resource communities. [[GitHub]](https://github.com/ducth1903/sas-period-tracker)  
- **Jul 2024:**  Paper on mental burnout detection across Reddit communities accepted at **EMNLP 2024 (NLP4PI Workshop)**.  
- **Sept 2023:** Gave a lightning talk at the [National Early Research Scholars Program (ERSP) Conference 2023](https://sites.google.com/ucsd.edu/ersp/about/2023-ersp-national-conference-virtual).


---

## Selected Publications

1. **How to Fine-Tune Safely on a Budget: Model Adaptation Using Minimal Resources**  
   *EMNLP Industry Track 2025.*  
   **Anh C. Pham**, Mihir Thalanki, Michael Sun, Aditya Chaloo, Ankita Gupta, Tian Xia, Aditya Mate, Ehi Nosakhare, Soundararajan Srinivasan 
   [Paper]([https://aclanthology.org/2025.emnlp-industry.138/](https://aclanthology.org/2025.emnlp-industry.138.pdf)) • [Code](https://github.com/696DS-Safety-Alignment-Microsoft/safety-tuned-llamas) 

3. **Inferring Mental Burnout Discourse Across Reddit Communities**  
   *EMNLP 2024 NLP4PI Workshop.*  
   Nazanin Sabri, **Anh C. Pham**, Ishita Kakkar, Mai ElSherief 
   [Paper]([/files/acl2024_burnout.pdf](https://aclanthology.org/2024.nlp4pi-1.21.pdf))

4. **Fluent but Unfeeling: The Emotional Blind Spots of Language Models**  
   *ICWSM 2026 (to appear).*  
   Bangzhao Shu*, Isha Joshi*, Melissa Karnaze, **Anh C. Pham**, Ishita Kakkar, Sindhu Kothe, Arpine Hovasapian, Mai ElSherief 
   [Preprint](https://arxiv.org/pdf/2509.09593)

---

## Teaching Assistant
- **Fall 2025** (CS485) Intro to Natural Language Processing	
- **Spring 2025** (CS373) Intro to Computer Graphics	

---

## Contact
- **Email:** acpham [at] umass [dot] edu  
